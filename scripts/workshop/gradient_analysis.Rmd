---
title: "gradient_analysis"
author: "Daniel Suh"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---
I used this document as my instructions for most of this analysis. https://sites.ualberta.ca/~lkgray/uploads/7/3/6/2/7362679/07-gradientanalysis.pdf s

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

load packages
```{r}
library(tidyverse)
library(magrittr)
library(ecodist)
library(vegan)
library(here)
```

read data and make species and environmental matrices
```{r}
data <- read_csv(here("data/weighted_prev_competence_111220.csv"))


#make community matrix
community_mat <- data %>% dplyr::select(WetAltID, Month.1, AB2:AB8, AB9, AB20:AB42)
community_mat$Month.1 <- gsub("Month", "", community_mat$Month.1) 
community_mat %<>% mutate(., siteID = paste(WetAltID, Month.1, sep = "_")) %>% 
  distinct() %>% arrange(.,WetAltID) %>% dplyr::select(-WetAltID, -Month.1) %>% dplyr::select(siteID, AB2:AB42)

community_mat %<>% column_to_rownames(., var = "siteID")


#select for environmental variables
env <- data %>% dplyr::select(WetAltID, Month.1, MeanAirT, MeanWaterTempPredC, DryingScore, CanopyCover, Area, Perimeter) %>% distinct() %>% arrange(.,WetAltID) 
env$Month.1 <- gsub("Month", "", env$Month.1)
#make siteID rowname
env$siteID <- paste(env$WetAltID, env$Month.1, sep = "_")
env %<>% dplyr::select(-WetAltID, -Month.1)
#remove duplicated rows (siteID is duplicated but env. variables are not... not sure why this is)
env <- env[-c(53, 90),]
env_mat <- env %>% column_to_rownames(., var = "siteID")

#replace NA's with zeros. Probably not the best option but will allow analysis to run for now
community_mat[is.na(community_mat)] <- 0
env_mat[is.na(env_mat)] <- 0

nrow(community_mat) == nrow(env_mat)

site_labels <- rownames(community_mat)
```

Gradient Analysis - a number of distance-based or rotation-based techniques for ordinating data to reduce the dimensions of data in order to compare two related datasets. A large number of independent variables require many degrees of freedoms and large number of observations. Gradient analysis allows for studying relationship between variables when the number of observations is limited to perform standard statistical procedures. Ordination allows for the reduction of data to ordination scores so that other variables can be correlated to ordination scores.


NMDS: non-metric multidimensional scaling - a distance-based ordination method
```{r}
#bray-curtis dissimilarity scores
spec_dist <- bcdist(community_mat)
spec_nmds <- nmds(spec_dist, mindim = 2, maxdim = 2)
spec_scores <- nmds.min(spec_nmds)

#mahalanobis dissimilarity scoring for sites by environmental variables
env_dist <- ecodist::distance(env_mat, method = "mahalanobis")
env_nmds <- nmds(env_dist, mindim = 2, maxdim = 2)
env_scores <- nmds.min(env_nmds)
```

Direct Gradient Analysis with NMDS
```{r}
####Direct GA w/ NMDS####
#Ordinate independent variable (environment)
#correlate species as vectors to ordination scores
plot(env_scores, col="white") 
vectors=vf(env_scores, env_mat, nperm=100) 
plot(vectors, col="red")

vectors=vf(env_scores, community_mat, nperm=100) 
plot(vectors, ascale=1, col="blue")
#### useful for understanding species composition only in light of the measured independent variables
#### other patterns that might be due to other independent variables are effectively ignored
```

Indirect Gradient Analysis with NMDS
```{r}
####Indirect GA w/ NMDS####
#Ordinate dependent variable (species)
#correlate ordination scores with independent variable (environment)
plot(spec_scores, col="white") 
vectors=vf(spec_scores, community_mat, nperm=100) 
plot(vectors, col="red")

vectors=vf(spec_scores, env_mat, nperm=100) 
plot(vectors, ascale=1, col="blue")
#### useful for understanding the similarity in species composition between sites regardless of independent variable
#### independent variable is then correlated to species but patterns may have been driven by other independent variables not measured
```

PCA: Principal Component Analysis - a rotation-based ordination method
```{r}
#Direct Gradient Analysis w/ PCA
pca_env_output <- princomp(env_mat, cor=T) # PCA
biplot(pca_env_output) # Generates a bi-plot with vectors
vec1 <- envfit(pca_env_output$score[,1:2], community_mat, permutations=0) 
plot(vec1, col="blue")

pca_env_scores <- pca_env_output$score[,1:2] # get the PC1 and PC2 scores 
pca_env_spec_scores <- cbind(pca_env_scores,community_mat) # merge with species 
correlations <- cor(pca_env_spec_scores) # calculate correlations
correlations12 <- correlations[3:23,1:2] # the loadings we want

#pca on community matrix and gather scores for first two principal components
pca <- princomp(community_mat, scores = TRUE)
p_spec_scores <- as.data.frame(pca$scores)
p_spec_scores %<>% dplyr::select(Comp.1, Comp.2) %>% rownames_to_column(., var = "siteID")


env_scores <- as.data.frame(pca_env_output$scores)
env_scores %<>% dplyr::select(Comp.1, Comp.2) %>% rownames_to_column(., var = "siteID")


```

Indirect Grdient Analysis using PCA
explanation of how envfit actually works -> https://stackoverflow.com/questions/60953996/how-are-envfit-results-created 
```{r}
#sites ordinated by species abundances
#cor = F to use correlation matrix because variables are all on same scale
species_pca <- princomp(community_mat, cor = F)
#plot(species_pca$scores, pch = 16)
summary(species_pca)
#loadings(species_pca)
#scores(species_pca)
biplot(species_pca)

env_fit_vectors <- envfit(species_pca, env_mat)

biplot(species_pca)
plot(env_fit_vectors)
```

What is the difference between the scores for species from envfit and the values from the correlation between environmental ordination scores and the community matrix?

```{r}
comm_summ <- data %>% dplyr::select(WetAltID, Month.1, Month, cc, Month, AB2:AB42, Prevalence, MeanWaterTempPredC) %>% 
  dplyr::select(-ABAmb, -ABSal) %>%  
  mutate(., size = rowSums(.[5:25]), 
    ABHigh = (AB9 + AB21 + AB26 + AB42), 
    ABLow = (AB2 + AB3 + AB4 + AB5 + AB6 + AB8 + AB20 + AB24 + AB27 + AB28 + AB29 + AB31 + AB34 + AB35 + AB38 + AB39 + AB41)) %>% #get totals for community size
  mutate(., siteID = paste(WetAltID, Month.1, sep = "_")) %>%
  distinct()
comm_summ$siteID <- gsub("Month", "", comm_summ$siteID)
```






```{r}
community_mat <- data %>% dplyr::select(WetAltID, Month.1, AB2:AB8, AB9, AB20:AB42) 
community_mat$Month <- gsub("Month", "", community_mat$Month.1)
community_mat %<>% mutate(., siteID = paste(WetAltID, Month, sep = "_")) %>% distinct() %>% arrange(.,WetAltID) %>% dplyr::select(siteID, AB2:AB42)

#make abundance and pres/abs matrices with rownames as siteIDs
abundance_mat <- community_mat %>% column_to_rownames(., var = "siteID")
presence_mat <- as.data.frame(ifelse(abundance_mat>0, 1, 0))
```



Principal Component Ranking may not be reliable as a proxy for community similarity because of double-zeroes

If two sites both have zeroes for a species then that does not show that a site is similar but only shows that both sites may be unsuitable for the species

Bray-Curtis dissimilarity does not face this limitation

But the question is how similar are sites with the similar community competence?

sometimes similar and sometimes not



## next step

do PCA after Hellinger transformation of data. PCA has the double zero problem but Hellinger distance avoids that problem and avoids overweighting of abundance data by turning absolute species abundances into relative abundances. more info [here](https://davidzeleny.net/blog/2022/03/17/euclidean-distance-is-sensitive-to-double-zero-problem-while-hellinger-is-not-visualization/)


```{r}
pca <- princomp(abundance_mat)

biplot(pca)

abundance_hellinger <- decostand(log1p(abundance_mat), 'hellinger')

tb_pca <- princomp(abundance_hellinger)

biplot(tb_pca)
```



```{r}
tb_pca_scores <- as.data.frame(tb_pca$scores) %>% dplyr::select(Comp.1, Comp.2) %>% rownames_to_column(., var = "siteID")

tb_pca_scores_summ <- left_join(comm_summ, tb_pca_scores, by = "siteID")

tb_pca_scores_summ$Month <- factor(tb_pca_scores_summ$Month, levels = c("Feb", "Mar", "Apr", "May", "Jun", "Jul"))

tb_pca_scores_summ %<>% mutate(pc1Rank=dense_rank(Comp.1))

tb_pca_scores_summ %>% ggplot(.,aes(x=pc1Rank, y=cc)) + geom_point()

tb_pca_scores_summ %>% ggplot(.,aes(x=Comp.1, y=cc)) + geom_point() + geom_smooth(method = "loess")

tb_pca_scores_summ %>% ggplot(.,aes(x=pc1Rank, y=cc)) + geom_point(aes(color = Month, shape = factor(WetAltID), size = size))+
  labs(x="Principal Component 1", y = "Community Competence (CC)", size = "Host\nAbundance") + 
  scale_shape_manual(values = rep(1:20, len = 20)) +
  scale_size_continuous(range = c(2,10)) +
  guides(shape=F) +
  theme_classic() +
  theme(aspect.ratio=1/1.618, legend.box = "horizontal") +
  scale_color_viridis_d(direction = -1) +
  theme(text = element_text(size=18))

```


NMDS with bray-curtis
```{r}
set.seed(8878896)
nmds <- metaMDS(abundance_mat, distance = "bray")

plot(nmds)

nmds_scores <- as_tibble(scores(nmds))
nmds_scores$siteID <- community_mat$siteID

nmds_scores_summ <- left_join(comm_summ, nmds_scores, by = "siteID")
nmds_scores_summ$Month <- factor(nmds_scores_summ$Month, levels = c("Feb", "Mar", "Apr", "May", "Jun", "Jul"))
nmds_scores_summ %<>% mutate(pc1Rank=dense_rank(NMDS1))

nmds_scores_summ %>% ggplot(.,aes(x=NMDS1, y = cc)) + geom_point() + geom_smooth(method = "loess")
```